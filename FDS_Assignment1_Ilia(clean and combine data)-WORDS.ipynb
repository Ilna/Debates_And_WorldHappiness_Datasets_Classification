{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Data Combination and Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Speech Dataset**"
   ],
   "metadata": {
    "id": "44da3690"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load speech dataframe\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sessions = np.arange(25, 76)\n",
    "data=[]\n",
    "\n",
    "for session in sessions:\n",
    "    directory = \"./TXT/Session \"+str(session)+\" - \"+str(1945+session)\n",
    "    for filename in os.listdir(directory):\n",
    "        f = open(os.path.join(directory, filename), encoding=\"utf8\")\n",
    "        if filename[0]==\".\": #ignore hidden files\n",
    "            continue\n",
    "        splt = filename.split(\"_\")\n",
    "        data.append([session, 1945+session, splt[0], f.read()])\n",
    "\n",
    "        \n",
    "df_speech = pd.DataFrame(data, columns=['Session','Year','ISO-alpha3 Code','Speech'])"
   ],
   "outputs": [],
   "metadata": {
    "id": "cd0b3ce3",
    "outputId": "2389f396-4af3-408f-ead4-16e595e79676"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Country-Name Dataset**"
   ],
   "metadata": {
    "id": "44da3690"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load UNSD dataframe(basically is the country-name dataset)\n",
    "n = 16 #define the columns\n",
    "\n",
    "# Load all the data using lineterminator = '\\n' to get all the  \n",
    "# columns that are misplaced because of the ',' inside them\n",
    "unsd_df = pd.read_csv('UNSD — Methodology.csv', usecols=range(n), lineterminator='\\n')\n",
    "unsd_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global Code</th>\n",
       "      <th>Global Name</th>\n",
       "      <th>Region Code</th>\n",
       "      <th>Region Name</th>\n",
       "      <th>Sub-region Code</th>\n",
       "      <th>Sub-region Name</th>\n",
       "      <th>Intermediate Region Code</th>\n",
       "      <th>Intermediate Region Name</th>\n",
       "      <th>Country or Area</th>\n",
       "      <th>M49 Code</th>\n",
       "      <th>ISO-alpha2 Code</th>\n",
       "      <th>ISO-alpha3 Code</th>\n",
       "      <th>Least Developed Countries (LDC)</th>\n",
       "      <th>Land Locked Developing Countries (LLDC)</th>\n",
       "      <th>Small Island Developing States (SIDS)</th>\n",
       "      <th>Developed / Developing Countries\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>012</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developing\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>818</td>\n",
       "      <td>EG</td>\n",
       "      <td>EGY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developing\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Libya</td>\n",
       "      <td>434</td>\n",
       "      <td>LY</td>\n",
       "      <td>LBY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developing\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>504</td>\n",
       "      <td>MA</td>\n",
       "      <td>MAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developing\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>729</td>\n",
       "      <td>SD</td>\n",
       "      <td>SDN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developing\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samoa</td>\n",
       "      <td>882</td>\n",
       "      <td>WS</td>\n",
       "      <td>WSM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>Developing\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tokelau</td>\n",
       "      <td>772</td>\n",
       "      <td>TK</td>\n",
       "      <td>TKL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developing\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonga</td>\n",
       "      <td>776</td>\n",
       "      <td>TO</td>\n",
       "      <td>TON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>Developing\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>798</td>\n",
       "      <td>TV</td>\n",
       "      <td>TUV</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>Developing\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wallis and Futuna Islands</td>\n",
       "      <td>876</td>\n",
       "      <td>WF</td>\n",
       "      <td>WLF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Global Code Global Name  Region Code Region Name  Sub-region Code  \\\n",
       "0              1       World          2.0      Africa             15.0   \n",
       "1              1       World          2.0      Africa             15.0   \n",
       "2              1       World          2.0      Africa             15.0   \n",
       "3              1       World          2.0      Africa             15.0   \n",
       "4              1       World          2.0      Africa             15.0   \n",
       "..           ...         ...          ...         ...              ...   \n",
       "244            1       World          9.0     Oceania             61.0   \n",
       "245            1       World          9.0     Oceania             61.0   \n",
       "246            1       World          9.0     Oceania             61.0   \n",
       "247            1       World          9.0     Oceania             61.0   \n",
       "248            1       World          9.0     Oceania             61.0   \n",
       "\n",
       "     Sub-region Name  Intermediate Region Code Intermediate Region Name  \\\n",
       "0    Northern Africa                       NaN                      NaN   \n",
       "1    Northern Africa                       NaN                      NaN   \n",
       "2    Northern Africa                       NaN                      NaN   \n",
       "3    Northern Africa                       NaN                      NaN   \n",
       "4    Northern Africa                       NaN                      NaN   \n",
       "..               ...                       ...                      ...   \n",
       "244        Polynesia                       NaN                      NaN   \n",
       "245        Polynesia                       NaN                      NaN   \n",
       "246        Polynesia                       NaN                      NaN   \n",
       "247        Polynesia                       NaN                      NaN   \n",
       "248        Polynesia                       NaN                      NaN   \n",
       "\n",
       "               Country or Area M49 Code ISO-alpha2 Code ISO-alpha3 Code  \\\n",
       "0                      Algeria      012              DZ             DZA   \n",
       "1                        Egypt      818              EG             EGY   \n",
       "2                        Libya      434              LY             LBY   \n",
       "3                      Morocco      504              MA             MAR   \n",
       "4                        Sudan      729              SD             SDN   \n",
       "..                         ...      ...             ...             ...   \n",
       "244                      Samoa      882              WS             WSM   \n",
       "245                    Tokelau      772              TK             TKL   \n",
       "246                      Tonga      776              TO             TON   \n",
       "247                     Tuvalu      798              TV             TUV   \n",
       "248  Wallis and Futuna Islands      876              WF             WLF   \n",
       "\n",
       "    Least Developed Countries (LDC) Land Locked Developing Countries (LLDC)  \\\n",
       "0                               NaN                                     NaN   \n",
       "1                               NaN                                     NaN   \n",
       "2                               NaN                                     NaN   \n",
       "3                               NaN                                     NaN   \n",
       "4                                 x                                     NaN   \n",
       "..                              ...                                     ...   \n",
       "244                             NaN                                     NaN   \n",
       "245                             NaN                                     NaN   \n",
       "246                             NaN                                     NaN   \n",
       "247                               x                                     NaN   \n",
       "248                             NaN                                     NaN   \n",
       "\n",
       "    Small Island Developing States (SIDS) Developed / Developing Countries\\r  \n",
       "0                                     NaN                       Developing\\r  \n",
       "1                                     NaN                       Developing\\r  \n",
       "2                                     NaN                       Developing\\r  \n",
       "3                                     NaN                       Developing\\r  \n",
       "4                                     NaN                       Developing\\r  \n",
       "..                                    ...                                ...  \n",
       "244                                     x                       Developing\\r  \n",
       "245                                   NaN                       Developing\\r  \n",
       "246                                     x                       Developing\\r  \n",
       "247                                     x                       Developing\\r  \n",
       "248                                   NaN                         Developing  \n",
       "\n",
       "[249 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Rename last column - remove the space(\\s)\n",
    "unsd_df.rename(columns={'Developed / Developing Countries\\r': 'Developed / Developing Countries'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Complete/Combine the name of the \"Country or Area\" that was misplaced into  \n",
    "# the M49 Code column and adjust all other columns\n",
    "\n",
    "for i,j in unsd_df[\"M49 Code\"].items():\n",
    "    if(len(j)>3):\n",
    "        unsd_df.iloc[i, unsd_df.columns.get_loc('Country or Area')] += j\n",
    "        unsd_df.iloc[i, unsd_df.columns.get_loc('M49 Code')] = unsd_df.iloc[i, unsd_df.columns.get_loc('ISO-alpha2 Code')]\n",
    "        unsd_df.iloc[i, unsd_df.columns.get_loc('ISO-alpha2 Code')] = unsd_df.iloc[i, unsd_df.columns.get_loc('ISO-alpha3 Code')]\n",
    "        unsd_df.iloc[i, unsd_df.columns.get_loc('ISO-alpha3 Code')] = unsd_df.iloc[i, unsd_df.columns.get_loc('Least Developed Countries (LDC)')]\n",
    "        unsd_df.iloc[i, unsd_df.columns.get_loc('Least Developed Countries (LDC)')] = unsd_df.iloc[i, unsd_df.columns.get_loc('Land Locked Developing Countries (LLDC)')]\n",
    "        unsd_df.iloc[i, unsd_df.columns.get_loc('Land Locked Developing Countries (LLDC)')] = unsd_df.iloc[i, unsd_df.columns.get_loc('Small Island Developing States (SIDS)')]        \n",
    "        unsd_df.iloc[i, unsd_df.columns.get_loc('Small Island Developing States (SIDS)')] = unsd_df.iloc[i, unsd_df.columns.get_loc('Developed / Developing Countries')]\n",
    "        unsd_df.iloc[i, unsd_df.columns.get_loc('Developed / Developing Countries')] = \"Developing\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Merge Speech and Country-Name dataframe\n",
    "speech_and_unsd_df = pd.merge(unsd_df, df_speech, on=\"ISO-alpha3 Code\")\n",
    "\n",
    "# Select specific columns to the final Speech and Country-Name dataframe\n",
    "speech_and_countryName_df = speech_and_unsd_df[['Region Name', 'Country or Area', 'Session', 'Year', 'Speech']].copy()\n",
    "speech_and_countryName_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region Name</th>\n",
       "      <th>Country or Area</th>\n",
       "      <th>Session</th>\n",
       "      <th>Year</th>\n",
       "      <th>Speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>1.  The delegation of Algeria is very pleased ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>26</td>\n",
       "      <td>1971</td>\n",
       "      <td>\\n154.\\t : It is not only in order to keep up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>27</td>\n",
       "      <td>1972</td>\n",
       "      <td>Mr. President, in electing you to preside over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28</td>\n",
       "      <td>1973</td>\n",
       "      <td>﻿121.\\tMr. President, since a tradition appear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>29</td>\n",
       "      <td>1974</td>\n",
       "      <td>Mr. President, it would be ungracious of the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>Oceania</td>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>71</td>\n",
       "      <td>2016</td>\n",
       "      <td>On behalf of the Government and people of Tuva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8380</th>\n",
       "      <td>Oceania</td>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>72</td>\n",
       "      <td>2017</td>\n",
       "      <td>Next week, on 1 October, Tuvalu will mark the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8381</th>\n",
       "      <td>Oceania</td>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>73</td>\n",
       "      <td>2018</td>\n",
       "      <td>It gives me great pleasure, on behalf of the G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8382</th>\n",
       "      <td>Oceania</td>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>74</td>\n",
       "      <td>2019</td>\n",
       "      <td>On behalf of Tuvalu and on my own behalf, I co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8383</th>\n",
       "      <td>Oceania</td>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>75</td>\n",
       "      <td>2020</td>\n",
       "      <td>Mr. President, Distinguished members of the Ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8384 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Region Name Country or Area  Session  Year  \\\n",
       "0         Africa         Algeria       25  1970   \n",
       "1         Africa         Algeria       26  1971   \n",
       "2         Africa         Algeria       27  1972   \n",
       "3         Africa         Algeria       28  1973   \n",
       "4         Africa         Algeria       29  1974   \n",
       "...          ...             ...      ...   ...   \n",
       "8379     Oceania          Tuvalu       71  2016   \n",
       "8380     Oceania          Tuvalu       72  2017   \n",
       "8381     Oceania          Tuvalu       73  2018   \n",
       "8382     Oceania          Tuvalu       74  2019   \n",
       "8383     Oceania          Tuvalu       75  2020   \n",
       "\n",
       "                                                 Speech  \n",
       "0     1.  The delegation of Algeria is very pleased ...  \n",
       "1     \\n154.\\t : It is not only in order to keep up ...  \n",
       "2     Mr. President, in electing you to preside over...  \n",
       "3     ﻿121.\\tMr. President, since a tradition appear...  \n",
       "4     Mr. President, it would be ungracious of the r...  \n",
       "...                                                 ...  \n",
       "8379  On behalf of the Government and people of Tuva...  \n",
       "8380  Next week, on 1 October, Tuvalu will mark the ...  \n",
       "8381  It gives me great pleasure, on behalf of the G...  \n",
       "8382  On behalf of Tuvalu and on my own behalf, I co...  \n",
       "8383  Mr. President, Distinguished members of the Ge...  \n",
       "\n",
       "[8384 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {
    "id": "cde2a21b",
    "outputId": "00428c18-fc02-4953-f6d3-d1921abc52d4",
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Happiness Dataset**"
   ],
   "metadata": {
    "id": "44da3690"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Load hapiness dataframe\n",
    "happinessdataframe = pd.read_excel('DataPanelWHR2021C2.xls', index_col=[0,1])\n",
    "happinessdataframe"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country name</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Afghanistan</th>\n",
       "      <th>2008</th>\n",
       "      <td>3.723590</td>\n",
       "      <td>7.370100</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>50.799999</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.167640</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>4.401778</td>\n",
       "      <td>7.539972</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>51.200001</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.190099</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>4.758381</td>\n",
       "      <td>7.646709</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>51.599998</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.120590</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>3.831719</td>\n",
       "      <td>7.619532</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>51.919998</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>3.782938</td>\n",
       "      <td>7.705479</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>52.240002</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.236032</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Zimbabwe</th>\n",
       "      <th>2016</th>\n",
       "      <td>3.735400</td>\n",
       "      <td>7.984372</td>\n",
       "      <td>0.768425</td>\n",
       "      <td>54.400002</td>\n",
       "      <td>0.732971</td>\n",
       "      <td>-0.094634</td>\n",
       "      <td>0.723612</td>\n",
       "      <td>0.737636</td>\n",
       "      <td>0.208555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>3.638300</td>\n",
       "      <td>8.015738</td>\n",
       "      <td>0.754147</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.752826</td>\n",
       "      <td>-0.097645</td>\n",
       "      <td>0.751208</td>\n",
       "      <td>0.806428</td>\n",
       "      <td>0.224051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3.616480</td>\n",
       "      <td>8.048798</td>\n",
       "      <td>0.775388</td>\n",
       "      <td>55.599998</td>\n",
       "      <td>0.762675</td>\n",
       "      <td>-0.068427</td>\n",
       "      <td>0.844209</td>\n",
       "      <td>0.710119</td>\n",
       "      <td>0.211726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2.693523</td>\n",
       "      <td>7.950132</td>\n",
       "      <td>0.759162</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>0.631908</td>\n",
       "      <td>-0.063791</td>\n",
       "      <td>0.830652</td>\n",
       "      <td>0.716004</td>\n",
       "      <td>0.235354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>3.159802</td>\n",
       "      <td>7.828757</td>\n",
       "      <td>0.717243</td>\n",
       "      <td>56.799999</td>\n",
       "      <td>0.643303</td>\n",
       "      <td>-0.008696</td>\n",
       "      <td>0.788523</td>\n",
       "      <td>0.702573</td>\n",
       "      <td>0.345736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1949 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Life Ladder  Log GDP per capita  Social support  \\\n",
       "Country name year                                                    \n",
       "Afghanistan  2008     3.723590            7.370100        0.450662   \n",
       "             2009     4.401778            7.539972        0.552308   \n",
       "             2010     4.758381            7.646709        0.539075   \n",
       "             2011     3.831719            7.619532        0.521104   \n",
       "             2012     3.782938            7.705479        0.520637   \n",
       "...                        ...                 ...             ...   \n",
       "Zimbabwe     2016     3.735400            7.984372        0.768425   \n",
       "             2017     3.638300            8.015738        0.754147   \n",
       "             2018     3.616480            8.048798        0.775388   \n",
       "             2019     2.693523            7.950132        0.759162   \n",
       "             2020     3.159802            7.828757        0.717243   \n",
       "\n",
       "                   Healthy life expectancy at birth  \\\n",
       "Country name year                                     \n",
       "Afghanistan  2008                         50.799999   \n",
       "             2009                         51.200001   \n",
       "             2010                         51.599998   \n",
       "             2011                         51.919998   \n",
       "             2012                         52.240002   \n",
       "...                                             ...   \n",
       "Zimbabwe     2016                         54.400002   \n",
       "             2017                         55.000000   \n",
       "             2018                         55.599998   \n",
       "             2019                         56.200001   \n",
       "             2020                         56.799999   \n",
       "\n",
       "                   Freedom to make life choices  Generosity  \\\n",
       "Country name year                                             \n",
       "Afghanistan  2008                      0.718114    0.167640   \n",
       "             2009                      0.678896    0.190099   \n",
       "             2010                      0.600127    0.120590   \n",
       "             2011                      0.495901    0.162427   \n",
       "             2012                      0.530935    0.236032   \n",
       "...                                         ...         ...   \n",
       "Zimbabwe     2016                      0.732971   -0.094634   \n",
       "             2017                      0.752826   -0.097645   \n",
       "             2018                      0.762675   -0.068427   \n",
       "             2019                      0.631908   -0.063791   \n",
       "             2020                      0.643303   -0.008696   \n",
       "\n",
       "                   Perceptions of corruption  Positive affect  Negative affect  \n",
       "Country name year                                                               \n",
       "Afghanistan  2008                   0.881686         0.517637         0.258195  \n",
       "             2009                   0.850035         0.583926         0.237092  \n",
       "             2010                   0.706766         0.618265         0.275324  \n",
       "             2011                   0.731109         0.611387         0.267175  \n",
       "             2012                   0.775620         0.710385         0.267919  \n",
       "...                                      ...              ...              ...  \n",
       "Zimbabwe     2016                   0.723612         0.737636         0.208555  \n",
       "             2017                   0.751208         0.806428         0.224051  \n",
       "             2018                   0.844209         0.710119         0.211726  \n",
       "             2019                   0.830652         0.716004         0.235354  \n",
       "             2020                   0.788523         0.702573         0.345736  \n",
       "\n",
       "[1949 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# happinessdataframe rename index from 'Country name' to'Country or Area'\n",
    "happinessdataframe.index.names = ['Country or Area', 'Year']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Merge Speech-Country-Name dataframe with the Happiness dataframe \n",
    "# on the columns 'Country or Area' and 'Year' \n",
    "all_data_df = pd.merge(speech_and_countryName_df, happinessdataframe, left_on=['Country or Area','Year'], right_on=['Country or Area','Year'], right_index=True)\n",
    "\n",
    "# Create indexes on the columns 'Country or Area' and 'Year' \n",
    "all_data_df = all_data_df.set_index(['Country or Area','Year'])\n",
    "\n",
    "# Create two dataframes one for speeches tokenized, and one for speeches tokennized and FreqDist\n",
    "all_data_tokenized_df = all_data_df.copy()\n",
    "all_data_tokenized_FreqDist_df = all_data_df.copy()\n",
    "data_word_vector_df = all_data_df[[\"Speech\"]].copy()\n",
    "\n",
    "# This is the unmerged Speech dataset\n",
    "data_word_vector_df_unmerged = speech_and_countryName_df\n",
    "data_word_vector_df_unmerged =data_word_vector_df_unmerged.set_index([\"Country or Area\",\"Year\"])\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download (in case you haven't already done so)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import nltk\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('vader_lexicon')"
   ],
   "outputs": [],
   "metadata": {
    "id": "d49d6e45",
    "outputId": "77120fca-6e61-45a6-c938-dc6bbe16bfb9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**OPTION 1) Run this if you want a dataframe merged with happiness**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "# Create all punctuation string variable\n",
    "punct = '!\"#$%&\\'()*+0123456789,’-—./:;<=>?@[\\\\]^_`{}~[\\n]'\n",
    "# Create a mapping table that will have as key the punctuation and as value an empty string\n",
    "transtab = str.maketrans(dict.fromkeys(punct, ''))\n",
    "\n",
    "# Loop through all the cells of \"Speech\" column\n",
    "for county_year_index,cell in data_word_vector_df[\"Speech\"].items():\n",
    "    # Remove all punctuations and convert the text to lowercase\n",
    "    words = word_tokenize(cell.translate(transtab).lower())\n",
    "    # Create an array that has all the words that don't give information\n",
    "    notuseful_words = stopwords.words(\"english\")\n",
    "    # Create and fill an empty array to gather all the important words of every \"Speech\" cell\n",
    "    useful_words = []\n",
    "    for w in words:\n",
    "        if (w not in notuseful_words) and (len(w) > 2):\n",
    "            useful_words.append(w)\n",
    "    # Fill the dataframe with the text of \"Speech\" for each cell\n",
    "    data_word_vector_df[\"Speech\"][county_year_index] = ' '.join(useful_words)\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**OPTION 2) You can run this instead of the above if you want to make a dataframe with word count from the unmerged example, it will take some minutes to finish around 2-4**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "# Create all punctuation string variable\n",
    "punct = '!\"#$%&\\'()*+0123456789,’-—./:;<=>?@[\\\\]^_`{}~[\\n]'\n",
    "# Create a mapping table that will have as key the punctuation and as value an empty string\n",
    "transtab = str.maketrans(dict.fromkeys(punct, ''))\n",
    "\n",
    "# Loop through all the cells of \"Speech\" column\n",
    "for county_year_index,cell in data_word_vector_df_unmerged[\"Speech\"].items():\n",
    "    # Remove all punctuations and convert the text to lowercase\n",
    "    words = word_tokenize(cell.translate(transtab).lower())\n",
    "    # Create an array that has all the words that don't give information\n",
    "    notuseful_words = stopwords.words(\"english\")\n",
    "    # Create and fill an empty array to gather all the important words of every \"Speech\" cell\n",
    "    useful_words = []\n",
    "    for w in words:\n",
    "        if (w not in notuseful_words) and (len(w) > 2):\n",
    "            useful_words.append(w)\n",
    "    # Fill the dataframe with the text of \"Speech\" for each cell\n",
    "    data_word_vector_df_unmerged[\"Speech\"][county_year_index] = ' '.join(useful_words)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-10-95104d1e9512>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_word_vector_df_unmerged[\"Speech\"][county_year_index] = ' '.join(useful_words)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "word_count_df = count_vect.fit_transform(data_word_vector_df[\"Speech\"])\n",
    "speechOnlyDf = pd.DataFrame(word_count_df.toarray() ,columns= count_vect.get_feature_names())\n",
    "\n",
    "word_count_df_unmerged = count_vect.fit_transform(data_word_vector_df_unmerged[\"Speech\"])\n",
    "speechOnlyDfUnmerged = pd.DataFrame.sparse.from_spmatrix(word_count_df_unmerged,columns=count_vect.get_feature_names())\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**This is used to create a happines and speech dataframe. It creates a dataframe with the whole speech merged with happiness**\\\n",
    "**You NEED to run this if you want the following cells to play |OR| You can skip some cells below, there are comments to find it**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "# Create all punctuation string variable\n",
    "punct = '!\"#$%&\\'()*+0123456789,’-—./:;<=>?@[\\\\]^_`{}~[\\n]'\n",
    "# Create a mapping table that will have as key the punctuation and as value an empty string\n",
    "transtab = str.maketrans(dict.fromkeys(punct, ''))\n",
    "\n",
    "# Loop through all the cells of \"Speech\" column\n",
    "for i,j in all_data_df[\"Speech\"].items():\n",
    "    # Remove all punctuations and convert the text to lowercase\n",
    "    words = word_tokenize(j.translate(transtab).lower())\n",
    "    # Create an array that has all the words that don't give information\n",
    "    sw = stopwords.words(\"english\")\n",
    "    # Create and fill an empty array to gather all the important words of every \"Speech\" cell\n",
    "    no_sw = []\n",
    "    for w in words:\n",
    "        if (w not in sw) and (len(w) > 2):\n",
    "            no_sw.append(w)\n",
    "    # Fill the dataframe with the tokenized \"Speech\" for each cell\n",
    "    all_data_tokenized_df[\"Speech\"][i] = no_sw\n",
    "    # Fill the dataframe with the word-count of the tokenized \"Speech\" for each cell\n",
    "    all_data_tokenized_FreqDist_df[\"Speech\"][i] = FreqDist(no_sw)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just some 1 visualization for better understanding and some useful keywords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_data_tokenized_FreqDist_df[\"Speech\"][1].plot(20)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Cleaning**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Observe the mean values for each numerical column\n",
    "all_data_tokenized_FreqDist_df.describe()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Count how many NaN values we have per column\n",
    "all_data_tokenized_FreqDist_df.isnull().sum()\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Here is depicted that the null values are all float64 type \n",
    "all_data_tokenized_FreqDist_df.dtypes"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keep one of the two approaches !!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Approach 2\n",
    "\n",
    "# Remove all NaN values\n",
    "all_data_tokenized_FreqDist_df =all_data_tokenized_FreqDist_df.dropna()\n",
    "\n",
    "all_data_tokenized_df =all_data_tokenized_df.dropna()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The only column that we should consider if it worthy to remove duplicates is \"Session\"\n",
    "\n",
    "# Food for thought\n",
    "# It is possible that there are two sessions rows with the same session for two different countries\n",
    "\n",
    "# all_data_tokenized_FreqDist_mean_df = all_data_tokenized_FreqDist_mean_df.drop_duplicates(subset=['Session'])\n",
    "# len(all_data_tokenized_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the available values in column \"Session\"\n",
    "all_data_tokenized_FreqDist_df['Session'].unique()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Removing Outliers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy import stats\n",
    "\n",
    "# A basic way to remove outliers with Z-score\n",
    "# Reference : https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame\n",
    "\n",
    "# I am not sure if we should remove the outliers ????\n",
    "\n",
    "# I do not think we should remove any outliers\n",
    "\n",
    "numeric_df = all_data_tokenized_FreqDist_df[['Life Ladder', 'Log GDP per capita', 'Social support', 'Healthy life expectancy at birth', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'Positive affect', 'Negative affect']].copy()\n",
    "all_data_tokenized_FreqDist_outliers_df = all_data_tokenized_FreqDist_df[(np.abs(stats.zscore(numeric_df)) < 3).all(axis=1)]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**----SKIP HERE IF YOU DIDN'T RUN THE CELL MENTIONED ABOVE----**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Join to create a very nice and handy dataframe of all words with index the country and year\n",
    "\n",
    "countryYearWordsUnmerged = pd.DataFrame()\n",
    "countryYearWordsUnmerged = speech_and_countryName_df.join(speechOnlyDfUnmerged)\n",
    "countryClassifierWordsUnmerged = speech_and_countryName_df.join(speechOnlyDfUnmerged)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Drop the speech column cause it contains all the info we dont need anymore\n",
    "countryYearWordsUnmerged= countryYearWordsUnmerged.drop([\"Speech\"], axis = 1)\n",
    "countryClassifierWordsUnmerged= countryClassifierWordsUnmerged.drop([\"Speech\"], axis = 1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Index by country and year\n",
    "\n",
    "countryYearWordsUnmerged.set_index([\"Country or Area\", \"Year\"],inplace=True)\n",
    "countryYearWordsUnmerged.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Region Name</th>\n",
       "      <th>Session</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aachen</th>\n",
       "      <th>aacknowledged</th>\n",
       "      <th>aacrev</th>\n",
       "      <th>aadd</th>\n",
       "      <th>aadda</th>\n",
       "      <th>aaddi</th>\n",
       "      <th>...</th>\n",
       "      <th>сөйлемек</th>\n",
       "      <th>тhomson</th>\n",
       "      <th>хxi</th>\n",
       "      <th>шмс</th>\n",
       "      <th>шоп</th>\n",
       "      <th>шьа</th>\n",
       "      <th>ьол</th>\n",
       "      <th>қарекет</th>\n",
       "      <th>қылмақ</th>\n",
       "      <th>ﬂagrant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country or Area</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Algeria</th>\n",
       "      <th>1970</th>\n",
       "      <td>Africa</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>Africa</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>Africa</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>Africa</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 330678 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Region Name  Session  aaa  aac  aachen  aacknowledged  \\\n",
       "Country or Area Year                                                         \n",
       "Algeria         1970      Africa       25    0    0       0              0   \n",
       "                1971      Africa       26    0    0       0              0   \n",
       "                1972      Africa       27    0    0       0              0   \n",
       "                1973      Africa       28    0    0       0              0   \n",
       "                1974      Africa       29    0    0       0              0   \n",
       "\n",
       "                      aacrev  aadd  aadda  aaddi  ...  сөйлемек  тhomson  хxi  \\\n",
       "Country or Area Year                              ...                           \n",
       "Algeria         1970       0     0      0      0  ...         0        0    0   \n",
       "                1971       0     0      0      0  ...         0        0    0   \n",
       "                1972       0     0      0      0  ...         0        0    0   \n",
       "                1973       0     1      0      0  ...         0        0    0   \n",
       "                1974       0     0      0      0  ...         0        0    0   \n",
       "\n",
       "                      шмс  шоп  шьа  ьол  қарекет  қылмақ  ﬂagrant  \n",
       "Country or Area Year                                                \n",
       "Algeria         1970    0    0    0    0        0       0        0  \n",
       "                1971    0    0    0    0        0       0        0  \n",
       "                1972    0    0    0    0        0       0        0  \n",
       "                1973    0    0    0    0        0       0        0  \n",
       "                1974    0    0    0    0        0       0        0  \n",
       "\n",
       "[5 rows x 330678 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop Session which is useless and reset the indexes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "\n",
    "countryYearWordsUnmerged =  countryYearWordsUnmerged.drop([\"Session\"], axis= 1)\n",
    "countryYearWordsUnmerged.reset_index(drop=True,inplace=True)\n",
    "countryYearWordsUnmerged.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region Name</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aachen</th>\n",
       "      <th>aacknowledged</th>\n",
       "      <th>aacrev</th>\n",
       "      <th>aadd</th>\n",
       "      <th>aadda</th>\n",
       "      <th>aaddi</th>\n",
       "      <th>aaddj</th>\n",
       "      <th>...</th>\n",
       "      <th>сөйлемек</th>\n",
       "      <th>тhomson</th>\n",
       "      <th>хxi</th>\n",
       "      <th>шмс</th>\n",
       "      <th>шоп</th>\n",
       "      <th>шьа</th>\n",
       "      <th>ьол</th>\n",
       "      <th>қарекет</th>\n",
       "      <th>қылмақ</th>\n",
       "      <th>ﬂagrant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 330677 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region Name  aaa  aac  aachen  aacknowledged  aacrev  aadd  aadda  aaddi  \\\n",
       "0      Africa    0    0       0              0       0     0      0      0   \n",
       "1      Africa    0    0       0              0       0     0      0      0   \n",
       "2      Africa    0    0       0              0       0     0      0      0   \n",
       "3      Africa    0    0       0              0       0     1      0      0   \n",
       "4      Africa    0    0       0              0       0     0      0      0   \n",
       "\n",
       "   aaddj  ...  сөйлемек  тhomson  хxi  шмс  шоп  шьа  ьол  қарекет  қылмақ  \\\n",
       "0      0  ...         0        0    0    0    0    0    0        0       0   \n",
       "1      0  ...         0        0    0    0    0    0    0        0       0   \n",
       "2      0  ...         0        0    0    0    0    0    0        0       0   \n",
       "3      0  ...         0        0    0    0    0    0    0        0       0   \n",
       "4      0  ...         0        0    0    0    0    0    0        0       0   \n",
       "\n",
       "   ﬂagrant  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 330677 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Turn Africa in 1 and other regions to 0, so we can see if we can predict African speeches"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "replace_values = { \"Africa\" : 1, \"Americas\" : 0,\"Europe\" : 0, \"Asia\" : 0, \"Oceania\" : 0}\n",
    "\n",
    "countryYearWordsUnmerged.replace({\"Region Name\" : replace_values}, inplace=True)\n",
    "countryYearWordsUnmerged.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region Name</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aachen</th>\n",
       "      <th>aacknowledged</th>\n",
       "      <th>aacrev</th>\n",
       "      <th>aadd</th>\n",
       "      <th>aadda</th>\n",
       "      <th>aaddi</th>\n",
       "      <th>aaddj</th>\n",
       "      <th>...</th>\n",
       "      <th>сөйлемек</th>\n",
       "      <th>тhomson</th>\n",
       "      <th>хxi</th>\n",
       "      <th>шмс</th>\n",
       "      <th>шоп</th>\n",
       "      <th>шьа</th>\n",
       "      <th>ьол</th>\n",
       "      <th>қарекет</th>\n",
       "      <th>қылмақ</th>\n",
       "      <th>ﬂagrant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8380</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8382</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8383</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 330677 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Region Name  aaa  aac  aachen  aacknowledged  aacrev  aadd  aadda  \\\n",
       "8379            0    0    0       0              0       0     0      0   \n",
       "8380            0    0    0       0              0       0     0      0   \n",
       "8381            0    0    0       0              0       0     0      0   \n",
       "8382            0    0    0       0              0       0     0      0   \n",
       "8383            0    0    0       0              0       0     0      0   \n",
       "\n",
       "      aaddi  aaddj  ...  сөйлемек  тhomson  хxi  шмс  шоп  шьа  ьол  қарекет  \\\n",
       "8379      0      0  ...         0        0    0    0    0    0    0        0   \n",
       "8380      0      0  ...         0        0    0    0    0    0    0        0   \n",
       "8381      0      0  ...         0        0    0    0    0    0    0        0   \n",
       "8382      0      0  ...         0        0    0    0    0    0    0        0   \n",
       "8383      0      0  ...         0        0    0    0    0    0    0        0   \n",
       "\n",
       "      қылмақ  ﬂagrant  \n",
       "8379       0        0  \n",
       "8380       0        0  \n",
       "8381       0        0  \n",
       "8382       0        0  \n",
       "8383       0        0  \n",
       "\n",
       "[5 rows x 330677 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Create the target, which is our region classification, and the data, which is our words**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "target= countryYearWordsUnmerged[\"Region Name\"]\n",
    "inputs = countryYearWordsUnmerged.drop(\"Region Name\", axis=\"columns\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make a split to our data set\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, target, test_size=0.2)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Info about our test and train sets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "len(x_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "839"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import MN Naive Bayes and fit our model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model= MultinomialNB(alpha= 0.01, fit_prior=False)\n",
    "model.fit(x_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, fit_prior=False)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our score\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "model.score(x_test,y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9570917759237187"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparameter Tuning with GridSearch\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "## DO NOT RUN THIS, IT TAKES 6 HOURS\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'alpha': (1, 1e-1, 1e-2, 1e-3),\n",
    "    'fit_prior': (True, False)\n",
    "}\n",
    "grid_model = GridSearchCV(estimator= model, param_grid= parameters, cv=5);\n",
    "grid_model = grid_model.fit(x_train,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best possible parameters and score for our model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "print(grid_model.best_score_)\n",
    "print(grid_model.best_params_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9610337972166997\n",
      "{'alpha': 0.01, 'fit_prior': False}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "------------ComplementNB implementation for country. This is the implementation for **Country Classification**------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "#Find the mode of countries\n",
    "\n",
    "countries = countryClassifierWordsUnmerged.loc[:,\"Country or Area\"].values\n",
    "countries = np.unique(countries)\n",
    "countriesOccuranceMode = countryClassifierWordsUnmerged[\"Country or Area\"].value_counts().mode\n",
    "countriesOccuranceMode"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Series.mode of Congo                         51\n",
       "Belarus                       51\n",
       "Iran (Islamic Republic of)    51\n",
       "Iceland                       51\n",
       "Indonesia                     51\n",
       "                              ..\n",
       "Kiribati                      18\n",
       "Holy See                      18\n",
       "Montenegro                    15\n",
       "Serbia                        15\n",
       "South Sudan                    9\n",
       "Name: Country or Area, Length: 195, dtype: int64>"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# Place the mode to filter countries that only fit that mode\n",
    "countriesUnique = countryClassifierWordsUnmerged[\"Country or Area\"].value_counts()\n",
    "countriesThatFitMode = countriesUnique[countriesUnique == 51] #The 51 is the mode we found earlier\n",
    "#Get a random country from the list\n",
    "randCountry = countriesThatFitMode.sample(n=1, random_state= 10)\n",
    "#Get country name\n",
    "randCountry = randCountry.index[0]\n",
    "#Add countries in a dictionary \n",
    "replaceDictionaryForCountries = {}\n",
    "for country in countries:\n",
    "  if country == randCountry:\n",
    "    replaceDictionaryForCountries[country] = 1\n",
    "  else:\n",
    "    replaceDictionaryForCountries[country] = 0\n",
    "# Split the set into target and input\n",
    "countryClassifierWordsUnmerged.replace({\"Country or Area\" : replaceDictionaryForCountries}, inplace=True)\n",
    "classTargets = countryClassifierWordsUnmerged[\"Country or Area\"]\n",
    "\n",
    "classInputs = countryClassifierWordsUnmerged.drop([\"Region Name\", \"Session\", \"Year\",\"Country or Area\"], axis=1)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "8379    0\n",
      "8380    0\n",
      "8381    0\n",
      "8382    0\n",
      "8383    0\n",
      "Name: Country or Area, Length: 8384, dtype: int64\n",
      "      aaa  aac  aachen  aacknowledged  aacrev  aadd  aadda  aaddi  aaddj  \\\n",
      "0       0    0       0              0       0     0      0      0      0   \n",
      "1       0    0       0              0       0     0      0      0      0   \n",
      "2       0    0       0              0       0     0      0      0      0   \n",
      "3       0    0       0              0       0     1      0      0      0   \n",
      "4       0    0       0              0       0     0      0      0      0   \n",
      "...   ...  ...     ...            ...     ...   ...    ...    ...    ...   \n",
      "8379    0    0       0              0       0     0      0      0      0   \n",
      "8380    0    0       0              0       0     0      0      0      0   \n",
      "8381    0    0       0              0       0     0      0      0      0   \n",
      "8382    0    0       0              0       0     0      0      0      0   \n",
      "8383    0    0       0              0       0     0      0      0      0   \n",
      "\n",
      "      aaddl  ...  сөйлемек  тhomson  хxi  шмс  шоп  шьа  ьол  қарекет  қылмақ  \\\n",
      "0         0  ...         0        0    0    0    0    0    0        0       0   \n",
      "1         0  ...         0        0    0    0    0    0    0        0       0   \n",
      "2         0  ...         0        0    0    0    0    0    0        0       0   \n",
      "3         0  ...         0        0    0    0    0    0    0        0       0   \n",
      "4         0  ...         0        0    0    0    0    0    0        0       0   \n",
      "...     ...  ...       ...      ...  ...  ...  ...  ...  ...      ...     ...   \n",
      "8379      0  ...         0        0    0    0    0    0    0        0       0   \n",
      "8380      0  ...         0        0    0    0    0    0    0        0       0   \n",
      "8381      0  ...         0        0    0    0    0    0    0        0       0   \n",
      "8382      0  ...         0        0    0    0    0    0    0        0       0   \n",
      "8383      0  ...         0        0    0    0    0    0    0        0       0   \n",
      "\n",
      "      ﬂagrant  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "8379        0  \n",
      "8380        0  \n",
      "8381        0  \n",
      "8382        0  \n",
      "8383        0  \n",
      "\n",
      "[8384 rows x 330676 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the countries set into data set and train set\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_words_train, x_words_test, y_country_train, y_country_test = train_test_split(classInputs, classTargets, test_size=0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement the Complement model\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "complementNBModel = ComplementNB(alpha = 0.01)\n",
    "complementNBModel.fit(x_words_train,y_country_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ComplementNB(alpha=0.01)"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "complementNBModel.score(x_words_test,y_country_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9904610492845787"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement the Multinomial model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multinomialNBModel= MultinomialNB(alpha= 0.01)\n",
    "multinomialNBModel.fit(x_words_train,y_country_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01)"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "multinomialNBModel.score(x_words_test,y_country_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9912559618441972"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab3-Assignment1-Aux.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}